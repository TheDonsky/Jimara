
/** _________________________________________________________________________________________________________ */
/** ############################################ RAY-GENERATION: ############################################ */
#pragma JM_LightingModelStage RayGeneration JM_RayGenShader, JM_NoLitShader;
#if RayGeneration

layout(set = MODEL_BINDING_SET_ID, binding = JIMARA_RT_MODEL_BINDING_BASE, rgba32ui) uniform readonly uimage2D JM_RayTracedRenderer_primitiveRecordId;
layout(rgba16f, set = MODEL_BINDING_SET_ID, binding = (JIMARA_RT_MODEL_BINDING_BASE + 1)) uniform image2D JM_RayTracedRenderer_frameColor;

layout(set = MODEL_BINDING_SET_ID, binding = (JIMARA_RT_MODEL_BINDING_BASE + 2)) uniform accelerationStructureEXT JM_RayTracedRenderer_tlas;

layout(location = 0) callableDataEXT Jimara_RayTracedRenderer_Standard_Call_Payload jimara_RayTracedRenderer_Call_Payload;


#define JM_RT_GetFragmentData(JM_RT_GetFragmentData_objectData, JM_RT_GetFragmentData_FragInfo, JM_RT_GetFragmentData_Query, JM_RT_GetFragmentData_committed) { \
	JM_RT_GetFragmentData_FragInfo.drawnObjectId = jimara_RayTracedRenderer_ViewportBuffer.rasterizedGeometrySize + \
		uint(rayQueryGetIntersectionInstanceCustomIndexEXT(JM_RT_GetFragmentData_Query, JM_RT_GetFragmentData_committed)); \
	JM_RT_GetFragmentData_FragInfo.barycentrics = rayQueryGetIntersectionBarycentricsEXT(JM_RT_GetFragmentData_Query, JM_RT_GetFragmentData_committed); \
	JM_RT_GetFragmentData_FragInfo.objectPrimitiveId = uint(rayQueryGetIntersectionPrimitiveIndexEXT(JM_RT_GetFragmentData_Query, JM_RT_GetFragmentData_committed)); \
	JM_RT_GetFragmentData_objectData = jimara_RayTracedRenderer_SceneObjectData.objectData[JM_RT_GetFragmentData_FragInfo.drawnObjectId]; \
	JM_RT_GetFragmentData_FragInfo.objectInstanceId = \
		uint(rayQueryGetIntersectionInstanceIdEXT(JM_RT_GetFragmentData_Query, JM_RT_GetFragmentData_committed)) - \
		JM_RT_GetFragmentData_objectData.firstBlasInstance; \
}

MaterialId_t GenerateFirstHitPayload(vec3 origin, vec3 dir, float minT, float maxT) {
	dir = normalize(dir);
	rayQueryEXT query;
	rayQueryInitializeEXT(
		query, JM_RayTracedRenderer_tlas,
		gl_RayFlagsCullBackFacingTrianglesEXT,
		0xFF, origin, minT, dir, maxT);
	while(rayQueryProceedEXT(query)) {
		// Get data:
		Jimara_RayTracedRenderer_PerObjectData objectData;
		JM_RT_GetFragmentData(objectData, jimara_RayTracedRenderer_Call_Payload.fragmentData, query, false);
		// No need to fill anything else from here; flags are called by the callable itself.

		// Discard if fragment should be discarded:
		executeCallableEXT(objectData.materialId * CALLABLE_STRIDE_PER_MATERIAL + CALLABLE_OFFSET_TRANSPARENCY_QUERY_CALL, 0);
		if ((jimara_RayTracedRenderer_Call_Payload.flags & JM_RT_PAYLOAD_FLAGS_DISCARD_POINT) != 0)
			continue;

		// Any-hit success:
		rayQueryConfirmIntersectionEXT(query);
	}
	if (rayQueryGetIntersectionTypeEXT(query, true) != 0) {
		// Get data:
		Jimara_RayTracedRenderer_PerObjectData objectData;
		JM_RT_GetFragmentData(objectData, jimara_RayTracedRenderer_Call_Payload.fragmentData, query, true);

		// Return material-id:
		return objectData.materialId;
	}
	// No hit - no material:
	else return INVALID_MATERIAL_ID;
}

MaterialId_t JM_RT_GeneratePixelPayload_FirstHit() {
	const float minT = 0.0001;
	return GenerateFirstHitPayload(
		jimara_RayTracedRenderer_Call_Payload.eyePosition, 
		jimara_RayTracedRenderer_Call_Payload.sampleDirection, minT, 
		jimara_RayTracedRenderer_ViewportBuffer.accelerationStructureRange);
}

MaterialId_t GeneratePixelPayload_FromVBuffer(in const ivec2 pixelIndex, in const vec2 frameUV) {
	const uvec4 primitiveRecordId = imageLoad(JM_RayTracedRenderer_primitiveRecordId, pixelIndex);
	jimara_RayTracedRenderer_Call_Payload.fragmentData.objectInstanceId = primitiveRecordId.x;
	jimara_RayTracedRenderer_Call_Payload.fragmentData.objectPrimitiveId = primitiveRecordId.y;
	jimara_RayTracedRenderer_Call_Payload.fragmentData.drawnObjectId = primitiveRecordId.z;

	if (jimara_RayTracedRenderer_Call_Payload.fragmentData.drawnObjectId == ~uint(0))
		return INVALID_MATERIAL_ID;

	Jimara_RayTracedRenderer_PerObjectData objectData = 
		jimara_RayTracedRenderer_SceneObjectData.objectData[jimara_RayTracedRenderer_Call_Payload.fragmentData.drawnObjectId];

	// __TODO__: We need a way to render edges too..
	if ((objectData.flags & JM_RT_FLAG_EDGES) != 0)
		return INVALID_MATERIAL_ID;

	{
		vec3 vertPosA, vertPosB, vertPosC;
		JM_RT_GetVertexPositions(
			jimara_RayTracedRenderer_Call_Payload.fragmentData.objectPrimitiveId, 
			jimara_RayTracedRenderer_Call_Payload.fragmentData.objectInstanceId, objectData, 
			vertPosA, vertPosB, vertPosC);

		jimara_RayTracedRenderer_Call_Payload.fragmentData.barycentrics = JM_RT_CalculateHitBarycentrics(
			vertPosA, vertPosB, vertPosC, 
			jimara_RayTracedRenderer_Call_Payload.eyePosition,
			jimara_RayTracedRenderer_Call_Payload.sampleDirection);
	}

	// If init fails, we should default to the first-hit:
	// Discard if fragment should be discarded:
	if ((jimara_RayTracedRenderer_ViewportBuffer.renderFlags & RENDERER_FLAGS_FALLBACK_ON_FIRST_RAY_IF_VBUFFER_EVAL_FAILS) != 0 &&
		(objectData.flags & JM_RT_FLAG_CAN_DISCARD) != 0) {
		executeCallableEXT(objectData.materialId * CALLABLE_STRIDE_PER_MATERIAL + CALLABLE_OFFSET_TRANSPARENCY_QUERY_CALL, 0);
		if ((jimara_RayTracedRenderer_Call_Payload.flags & JM_RT_PAYLOAD_FLAGS_DISCARD_POINT) != 0)
			return JM_RT_GeneratePixelPayload_FirstHit();
	}

	return objectData.materialId;
}

MaterialId_t JM_RT_GeneratePixelPayload() {
	const ivec2 pixelIndex = ivec2(gl_LaunchIDEXT.xy);
	const ivec2 targetSize = ivec2(imageSize(JM_RayTracedRenderer_frameColor));
	vec2 frameUV = vec2(pixelIndex) + 0.5;
	if (jimara_RayTracedRenderer_ViewportBuffer.sampleIndex > 0) {
		Jimara_RNG_t rng;
		const float sampleFrac = (1.0 / float(jimara_RayTracedRenderer_ViewportBuffer.sampleIndex + 1));
		JIMARA_RNG_seed(rng, 
			floatBitsToUint(frameUV.x),
			floatBitsToUint(frameUV.y),
			floatBitsToUint(float(pixelIndex.x)),
			floatBitsToUint(float(pixelIndex.y)),
			floatBitsToUint(sampleFrac));
		frameUV += vec2(Jimara_RNG_float(rng), Jimara_RNG_float(rng)) - 0.5;
	}
	frameUV = JM_RT_CalculateFrustrumSpacePosition(frameUV, targetSize);
	
	JM_RT_CalculateScreenSpaceRay(frameUV, 
		jimara_RayTracedRenderer_Call_Payload.eyePosition,
		jimara_RayTracedRenderer_Call_Payload.sampleDirection);

	{
		vec2 uv = JM_RT_CalculateFrustrumSpacePosition(vec2(pixelIndex), targetSize);
		vec3 startA, dirA;
		JM_RT_CalculateScreenSpaceRay(uv, startA, dirA);
		uv = JM_RT_CalculateFrustrumSpacePosition(vec2(pixelIndex) + 1.0, targetSize);
		vec3 startB, dirB;
		JM_RT_CalculateScreenSpaceRay(uv, startB, dirB);
		jimara_RayTracedRenderer_Call_Payload.startPatchSize = length(startB - startA);
		jimara_RayTracedRenderer_Call_Payload.patchSizeOverDistance = 
			(length(dirB - dirA) - jimara_RayTracedRenderer_Call_Payload.startPatchSize) / length(dirB + dirA);
		jimara_RayTracedRenderer_Call_Payload.startPatchSize *= 0.5;
	}

	if ((jimara_RayTracedRenderer_ViewportBuffer.renderFlags & RENDERER_FLAGS_USE_RASTER_VBUFFER) != 0)
		return GeneratePixelPayload_FromVBuffer(pixelIndex, frameUV);
	else return JM_RT_GeneratePixelPayload_FirstHit();
}

void main() {
	// Establish first payload:
	MaterialId_t materialId = JM_RT_GeneratePixelPayload();
	if (materialId == INVALID_MATERIAL_ID)
		return;
	
	// Fragment color and sample transmittance will be continually updated, so we need to initialize them here:
	jimara_RayTracedRenderer_Call_Payload.fragmentColor = vec4(0.0, 0.0, 0.0, 1.0);
	jimara_RayTracedRenderer_Call_Payload.sampleTransmittance = mat3(
		vec3(1.0, 0.0, 0.0),
		vec3(0.0, 1.0, 0.0),
		vec3(0.0, 0.0, 1.0));

	// Initial eye-position is the camera-position:
	vec3 eyePosition = jimara_RayTracedRenderer_Call_Payload.eyePosition;

	// Bounce-count countdown:
	uint bouncesLeft = jimara_RayTracedRenderer_ViewportBuffer.maxTraceDepth;

	while (true) {
		// Shade: 
		jimara_RayTracedRenderer_Call_Payload.eyePosition = eyePosition;
		if (bouncesLeft > 0) {
			jimara_RayTracedRenderer_Call_Payload.flags = JM_RT_PAYLOAD_FLAGS_INDIRECT_CAN_REQUEST_SAMPLE;
			bouncesLeft--;
		}
		else jimara_RayTracedRenderer_Call_Payload.flags = 0;
		executeCallableEXT(materialId * CALLABLE_STRIDE_PER_MATERIAL + CALLABLE_OFFSET_SHADE_FRAGMENT_CALL, 0);

		// If indirect sample is requested, update eye-position and material-id:
		if ((jimara_RayTracedRenderer_Call_Payload.flags & JM_RT_PAYLOAD_FLAGS_INDIRECT_SAMPLE_REQUESTED) != 0) {
			eyePosition = jimara_RayTracedRenderer_Call_Payload.eyePosition;
			const float minT = 0.0001;
			materialId = GenerateFirstHitPayload(eyePosition, jimara_RayTracedRenderer_Call_Payload.sampleDirection, 
				minT, 
				jimara_RayTracedRenderer_ViewportBuffer.accelerationStructureRange);
			if (materialId == INVALID_MATERIAL_ID)
				break;
			else jimara_RayTracedRenderer_Call_Payload.fragmentColor.xyz -= jimara_RayTracedRenderer_Call_Payload.irradianceColor;
		}
		else break;
	}

	if (jimara_RayTracedRenderer_ViewportBuffer.sampleIndex > 0) {
		const vec4 storedColor = imageLoad(JM_RayTracedRenderer_frameColor, ivec2(gl_LaunchIDEXT.xy));
		jimara_RayTracedRenderer_Call_Payload.fragmentColor = mix(
			storedColor, jimara_RayTracedRenderer_Call_Payload.fragmentColor,
			1.0 / float(jimara_RayTracedRenderer_ViewportBuffer.sampleIndex + 1));
	}
	imageStore(JM_RayTracedRenderer_frameColor, ivec2(gl_LaunchIDEXT.xy), jimara_RayTracedRenderer_Call_Payload.fragmentColor);
}
#endif // RayGeneration
