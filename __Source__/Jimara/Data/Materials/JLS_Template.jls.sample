/*
This file serves as a general guide and documentation for implementing new Lit-Shaders for Materials.
As a relatively simple example, one can use built-in Sample-Diffuse shader: https://github.com/TheDonsky/Jimara/blob/main/__Source__/Jimara/Data/Materials/SampleDiffuse/Jimara_SampleDiffuseShader.jls

To those unfamiliar with how Lit-Shader definitions functions within the engine's rendering architecture, here's a small overview:

. There are 3 major parts to most renderers:
	0. Light definition files (commonly found by extension '.jld'), which define individual light source types and the corresponding emission logic;
	1. Lit-Shaders (identified by '.jls' extension), explained in detail within this source file, which define material characteristics and surface physics;
	2. Lighting-Models (LM-s for short; identified by '.jlm' extension), which act as individual renderers for various purposes and contain all rendering logic, 
		as well as 'connective tissue' between the light emissions and lit-shaders.
		Examples of lighting models would be stuff like the Forward-Plus renderer used for scene rendering, Depth-only renderer used for certain shadows,
		ObjectId-Renderer used for scene-view selection and so on.

. Compilation happens in the following steps:
	0. Initially, all Light-Definition files are found, parsed and combined into one, with some additional boilerplate that later allows Lighting-Models
		to access the light-source emission functions just by knowing their type-id and providing settings buffer (more details are irrelevant for Lit-Shaders);
	1. For each Lit-Shader and Lighting-Model pair, a custom .glsl source file is generated that includes combined light-definition header,
		followed by the per-Lit-Shader boilerplate code derived from various configuration #pragma statements described below, 
		alonside the include statements for the Lit-Shader and the Lighting-Model;
	2. As the next step, the generated .glsl code is compiled for every LM-Stage and Shader-Stage combination defined within the lighting model 
		into a separate SPIRV-binary.
	3. Finally, a .json file is generated containing all the CPU-side information about the parameters, flags and options for each lit-shader,
		as well as a lookup table for In-engine utilities to be able to find the location of compiled shader bytecode.

. During runtime, the shaders and derived Material::LitShader objects are accessed through the ShaderLibrary interface.


As already stated above, this file in particular contains the spec and sort-of an example/guide for Lit-Shader definitions; Here are the "moving parts" involved:

. Firstly, each Lit-Shader has an "argument-block", named JM_MaterialProperties, which is derived from JM_MaterialProperty #pragma statements by the compiler.
	As a side-note to this, the same properties will be visible from material editor and will be modifiable through code during runtime;

. As a next thing, we have a general interface for vertex processing through Lit-Shader-defined JM_EvaluateVertex function.
	0. Said function gets JM_MaterialProperties, as well as the vertex buffer information through JM_VertexInput structure 
		built from Engine's standartized vertex input, expected to be supported by most graphics-object Components (like MeshRenderer or SkinnedMeshRenderer).
		Some of the fields contained within JM_VertexInput are optional and can be requested through JM_MaterialFlags (explained below);
	1. As an output, LM-s will expect JM_FragmentData, which is a struct generated by the compiler using JM_FragmentField #pragma statements (explained below).
		JM_FragmentData::JM_Position is a built-in vec3 for world-space position and can be used for Vector-displacement, 
		as long as the LM supports it, but that is not guranteed to be that case under all circumstances.
	2. As you might have guessed, some Lighting-Models may choose to use JM_EvaluateVertex inside a Vertex-shader, 
		pass the resulting JM_FragmentData to the Fragment-shader and continue rendering from there.
		Having said this, the function itself is not tied to any specific pipeline stage and when considering options like RT-pipelenes, 
		some custom compute-based software rendering, just plain tesselation and any number of potential algorithms behind the lighting-models,
		the actual logic may be dramatically different from that simplified assumption.
		In any case, this is our 'vertex-processing' interface; it optionally allows displacement and lets us perform some per-vertex precalculations if necessary.

. Beyond vertex-processing, lit-shaders are supposed to define multiple additional functions that will control Matrerial's interaction with light:
	0. JM_Init - A function, responsible for initializing the shading state, as well as [potentially] rejecting invalid/cutout fragments.
		As an input, initialization function gets interpolated JM_FragmentData and constant JM_MaterialProperties. 
		This is also the last function that gets direct reference to the argument-block and if there are any texture-sampling 
		or property-dependent calculations required, the results should be either precalculated and stored within the shading state, 
		or the [parts of the] JM_MaterialProperties should be stored within the shading state;
	1. JM_Opacity - Optional opacity getter for non-opaque materials;
	2. JM_Emission - Getter for "black-body-radiation" type emission from the surface of the material;
	3. JM_EvaluateBrdf - Function for calculating bidirectional reflectance distribution function of the surface,
		based on the shading state, light direction, it's color&type and view direction;
	4. JM_RequestBounceSample - A function for requesting bounce-light for indirect illumination/reflections.


Lighting-Models are allowed to invoke material interface functions in any order and any number of times, as long as the [in-type] arguments are initialized correctly;
Also, LM-s are not 'obligated' to support all features like bounce-light or vertex-displacement, 
so keep in mind that those are 'tools' for when both shader and LM support the feature, not 'demands' from the lit-shader.

The rest, along the finer details about each #pragma and interface function is explained below.

*/



// Each lit shader defines it's public name and path for the editor as follows:
#pragma JM_MaterialPath(name = "Example Mat", path = "Jimara/Example Mat", hint = "Material description");
// By default, name will be the same as the filename, path will be the relative path from the project root and hint will just refer to those two


// Each lit shader defines it's blending mode as follows:
#pragma JM_BlendMode JM_Blend_Opaque
// Avaliable choices are as follows:
// JM_Blend_Opaque   - Opaque;
// JM_Blend_Alpha    - Alpha-blended;
// JM_Blend_Additive - Additively-blended;
// (Cutouts are controlled by JM_CanDiscard material flag)
// Value of this pragma, as well as values of the blend-modes will be appended as macro definitions during compilation


// Lit shaders define which optional vertex inputs to use, 
// as well as some other optimization and/or features to use through JM_MaterialFlags:
#pragma JM_MaterialFlags (JM_CanDiscard | JM_UseVertexColor)
// Avaliable flags are as follows:
// JM_CanDiscard - Allows fragment discard when JM_Init fails;
// JM_UseObjectId - Exposes JM_ObjectIndex through JM_VertexInput
// JM_UsePerVertexTilingAndOffset - Exposes JM_ObjectTilingAndOffset through JM_VertexInput
// JM_UseVertexColor - Exposes JM_VertexColor through JM_VertexInput
// JM_UseTangents - Exposes derived tangent and bitangent vectors through JM_VertexInput
// Value of this pragma, as well as values of the blend-modes will be appended as macro definitions during compilation


// Each lit shader defines it's material properties like this:
#pragma JM_MaterialProperty float propertyName0;
#pragma JM_MaterialProperty() vec4 propertyName1;
#pragma JM_MaterialProperty(default = { 0, 1, 0 }, color = true) vec3 propertyName2;
#pragma JM_MaterialProperty(hint = "This will show-up as a hint when hovered in editor") vec3 propertyName3;
#pragma JM_MaterialProperty(alias = "Editor will show this instead of 'propertyName4'") mat4 propertyName4;
#pragma JM_MaterialProperty(alias = "Alias", hint = "Hint", default = 9, range = { 0, 10 }) int propertyName5;
#pragma JM_MaterialProperty() sampler2D propertyName6;
#pragma JM_MaterialProperty(default = { 0, 1, 0, 1 }) sampler2D propertyName7;
// etc...
#pragma JM_MaterialProperty float propertyNameN;
// ValueType can be any built-in numeric types or a sampler;
// Defaults are 0-values in case of numbers and 'white-texture' in case of samplers and images;
// Defaults do not need typenames and including those will cause errors! 
// Contents of the default values will not be validated untill the generated source compilation, so if there are issues, expect the compiler to fail with generated source.
// 'JM' and 'jm' prefixes are reserved for engine-defined variable names and should not be present in the definitions, unless specified.
// Current preprocessor DOES NOT support custom structure parsing and, because of that, they are not allowed for now; Expect that to change eventually.
// You can add arbitary attribute values to the properties like 'color = true' or 'range = { 0, 1 }', and they will appear in editor as long as they are supported 
// (currently, color and range are the only attributes, but in feauture we will have an API to support adding more custom serialization attributes)

// Shader compiler Will automatically create a corresponding structures for the lit shaders:
struct JM_MaterialPropertySampler_0 { uint id; }; // Structs can not contain sampler2D values directly, so we have this workaround; Shader code can just treat them as textures with extra steps
vec4 texture(in JM_MaterialPropertySampler_0 jm_tex, vec2 jm_uv);
struct JM_MaterialPropertySampler_1 { uint id; };
vec4 texture(in JM_MaterialPropertySampler_1 jm_tex, vec2 jm_uv);
// etc...
struct JM_MaterialProperties {
	float propertyName0;
	vec4 propertyName1;
	vec3 propertyName2;
	vec3 propertyName3;
	mat4 propertyName4;
	int propertyName5;
	JM_MaterialPropertySampler_0 propertyName6; // Structs can not contain sampler2D values directly, so we have this workaround; Shader code can just treat them as textures with extra steps
	JM_MaterialPropertySampler_1 propertyName7;
	// etc...
	float propertyNameN;
};


// Each lit-shader defines it's fragment shader inputs as follows:
#pragma JM_FragmentField float fieldName0;
#pragma JM_FragmentField vec3 fieldName1;
#pragma JM_FragmentField int fieldName2;
// etc...
#pragma JM_FragmentField TypeNameN fieldNameN;
// JM_Position is a reserved mandatory fragment-field and does not need a definition; 
// Having said that, the lit-shader is responsible for filling it and the lighting model may or may not support vertex displacement.
// In cases when the individual lighting models do not support vertex displacement within it's stages, 
// the drawn position will be (JM_ObjectTransform * vec4(JM_VertexPosition, 1.0)).xyz but the LMs may still use it for illuminating the fragment. 
// API for figuring out if the displacement is supported within LM will be provided at a feauture date.
//
// Integer JM_FragmentField entries are allowed, but keep in mind, that they may be subject to the limitations of vertex shader out-variables;
// Any type is allowed, as long as it has a well-defined mix(Type, Type, float) implementation 
// that EXACTLY MATCHES the rasterizer's fragment-in variable blending behaviour
// Keep in mind, that preprocessor will take no responsibility for making sure the typenames are valid and variable names can be used; Expect compiler error if you mess-up.

// Shader compiler Will automatically create a corresponding structure and helpers for the lit shader fragments:
struct JM_FragmentData {
	vec3 JM_Position;
	float fieldName0;
	vec3 fieldName1;
	int fieldName2;
	// etc...
	TypeNameN fieldNameN;
}
JM_FragmentData mix(JM_FragmentData a, JM_FragmentData b, float t);
// As side-note, currently there is no support for tesselation stages and also no support for in-shader-vector-displacement for ray-traced lighting models
// More will be added to the API if and when they get enabled.



// Fixed vertex input for all types (provided by lit-shader compiler):
struct JM_VertexInput {
	mat4 transform;			// JM_ObjectTransform;

	vec3 position;			// JM_VertexPosition
	vec3 normal;			// JM_VertexNormal
	vec2 uv;				// JM_VertexUV

#if (JM_MaterialFlags & JM_UseObjectId) != 0
	uint objectId;			// JM_ObjectIndex (optional; enabled via JM_MaterialFlags JM_UseObjectId flag)
#endif

#if (JM_MaterialFlags & JM_UsePerVertexTilingAndOffset) != 0
	vec4 tilingAndOffset;	// JM_ObjectTilingAndOffset (optional; enabled via JM_MaterialFlags JM_UsePerVertexTilingAndOffset flag)
#endif

#if (JM_MaterialFlags & JM_UseVertexColor) != 0
	vec4 vertexColor;		// JM_VertexColor (optional; enabled via JM_MaterialFlags JM_UseVertexColor flag)
#endif

#if (JM_MaterialFlags & JM_UseTangents) != 0
	vec3 tangent;			// Tangent vector, derived from JM_VertexPosition, JM_VertexNormal and JM_VertexUV members of the geometry
	vec3 bitangent;			// Bitangent vector, derived from JM_VertexPosition, JM_VertexNormal and JM_VertexUV members of the geometry
#endif
};

// Fixed light info for all types (provided by lit-shader compiler):
struct JM_BrdfQuery {
	vec3 lightDirection;	// Fragment-to-light direction
	vec3 viewDelta;			// Fragment-to-view/observer direction multiplied by distance
	vec3 color;				// Photon color/energy per-channel
	uint photonType;		// Photon sample type (view Jimara/Environment/Rendering/SceneObjects/Lights/Photon.glh for further details)
};

// Fixed sample request structure for all types (provided by lit-shader compiler):
struct JM_BounceSample {
	vec3 direction;			// Fragment-to-reflection-source direction
	mat3 colorTransform;	// colorTransform * JM_BrdfQuery.color will be assumed to be reflected color, without re-invoking JM_EvaluateBrdf when calculating reflections
};


// Has to be defined within material source:
struct JM_ShadingState {
	// Required:
	vec3 normal; 			// World-space normal
	float roughness;		// [0.0 - 1.0]

	// Any other shader-defined data goes here...
};
// Current preprocessor is unable to evaluate structure sizes and some lighting models might need to know about it;
// This is a temporary band-aid to allow that. Sometime later in the future, this will no longer be required.
#pragma JM_ShadingStateSize 64; // This values is just a placeholder; JM_ShadingState size should be measured with regular GLSL rules



// Has to be defined within material source:
JM_FragmentData JM_EvaluateVertex(in const JM_VertexInput vertexInput, in const JM_MaterialProperties materialProperties) {
	// User-Defined implementation...
}

// Has to be defined within material source:
bool JM_Init(in JM_FragmentData fragmentInput, in const JM_MaterialProperties materialProperties, out JM_ShadingState state) {
	// User-Defined implementation...
	return trueIfFragmentShouldNotBeDiscarded; // (false value may be ignored if JM_MaterialFlags does not contain JM_CanDiscard flag)
}

#if JM_BlendMode != JM_Blend_Opaque
// Has to be defined within material source:
float JM_Opacity(inout JM_ShadingState state) {
	// User-Defined implementation...
}
#endif

// Has to be defined within material source:
vec3 JM_Emission(inout JM_ShadingState state, in const vec3 viewDelta) {
	// Should return emission color.
}

// Has to be defined within material source:
vec3 JM_EvaluateBrdf(inout JM_ShadingState state, in const JM_BrdfQuery query) {
	// Should evaluate BRDF and return the color of the photon reflected in view/observer direction
}

// Has to be defined within material source:
bool JM_RequestBounceSample(inout JM_ShadingState state, in const vec3 viewDelta, out JM_BounceSample requestedSample) {
	// Should generate a bounce-sample request, store it's direction and color-response in requestedSample and return true, 
	// or return false if the surface does not need any bounce light.
}





// Lighting models will have access to the following structure and definitions, that will mirror the settings buffer from the host:
// (Lit-shaders can ignore these definitions)

// This will serve as the generated material's property buffer that can be bound directly or used with bindless index:
struct JM_MaterialProperties_Buffer {
	float jm_prop_propertyName0;
	uint jm_padding0, jm_padding1, jm_padding2; // Pad-variables will be added to make the alignment obvious. User should not care about those...
	vec4 jm_prop_propertyName1;
	// ...
	uint jm_prop_propertyName6; // Bindless-index instead of sampler2D
	// etc...
	float jm_prop_propertyNameN;
};

// GLSL does not have sizeof()... This will be calculated by compiler script:
#define JM_Materialproperties_BufferSize sizeof(JM_MaterialProperties_Buffer)

// Lighting model will be able to quickly get JM_MaterialProperties from JM_MaterialProperties_Buffer using this macro:
#define JM_MaterialPropertiesFromBuffer(/* JM_MaterialProperties_Buffer */ jm_buff) \
	JM_MaterialProperties( \
		jm_buff.jm_prop_propertyName0, \
		/* ... */ \
		JM_MaterialPropertySampler_0(jm_buff.jm_prop_propertyName6), \
		/* etc... */ \
		jm_buff.jm_prop_propertyNameN)

// For direct-bindings, lighting model can use this macro:
// . Non-texture settings will be bound to jm_MaterialSettingsBuffer with JM_MaterialProperties_Buffer data;
// . Textures will be bound by names jm_MaterialSamplerBinding0, jm_MaterialSamplerBinding1 and so on;
// . JM_MaterialPropertiesFromBindings() function will be generated for quick access to JM_MaterialProperties
#define JM_DefineDirectMaterialBindings(/* int */ jm_bindingSet, /* int */ jm_firstBinding) \
	layout(set = jm_bindingSet, binding = jm_firstBinding) uniform JM_MaterialSettingsBuffer { JM_MaterialProperties_Buffer data; } jm_MaterialSettingsBuffer; \
	layout(set = jm_bindingSet, binding = (jm_firstBinding + 1)) uniform sampler2D jm_MaterialSamplerBinding0; \
	/* Any other sampler2D properties... */ \
	JM_MaterialProperties JM_MaterialPropertiesFromBindings() { \
		return JM_MaterialPropertiesFromBuffer(jm_MaterialSettingsBuffer.data); \
	}

// In case binding set defined by JM_DefineDirectMaterialBindings needs to contain more entries, this macro will be exposed to the lighting models
#define JM_DirectMaterialBindingCount (TotalTextureBindingCount + 1)

// Depending on the context, the Lighting-model definition has a choice of providing texture support using one of these ways:

// For bindless case: just give something like jimara_BindlessTextures and uint/nonuniformEXT as arguments and it'll implement texture access through bindless indices.
#define JM_DefineTextureSupportWithBindlessSamplers(jm_samplers /* Bindless samplers */, jm_qualifier /* nonuniformEXT or uint */) \
	vec4 texture(in JM_MaterialPropertySampler_0 jm_tex, vec2 jm_uv) { return texture(jm_samplers[jm_qualifier(jm_tex.id)], jm_uv); } \
	vec4 texture(in JM_MaterialPropertySampler_1 jm_tex, vec2 jm_uv) { return texture(jm_samplers[jm_qualifier(jm_tex.id)], jm_uv); } \
	/* etc... */

// For direct-binding and 'exclusive material' case: As long as JM_DefineDirectMaterialBindings() is used, texture support can use direct bindings, ignoring the bindless indices.
#define JM_DefineTextureSupportWithDirectBindings() \
	vec4 texture(in JM_MaterialPropertySampler_0 jm_tex, vec2 jm_uv) { return texture(jm_MaterialSamplerBinding0, jm_uv); } \
	vec4 texture(in JM_MaterialPropertySampler_1 jm_tex, vec2 jm_uv) { return texture(jm_MaterialSamplerBinding1, jm_uv); } \
	/* etc... */
	